{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Launch Lab - Sea Ice Movement Challenge - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some more analysis on the data before choosing our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os \n",
    "pd.options.mode.chained_assignment = None\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import modules.ml_pipeline.readdata as mlpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from disk and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (329888, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>doy</th>\n",
       "      <th>id_buoy</th>\n",
       "      <th>sic_cdr</th>\n",
       "      <th>d2c</th>\n",
       "      <th>ice_thickness</th>\n",
       "      <th>buoy_lat</th>\n",
       "      <th>buoy_lon</th>\n",
       "      <th>buoy_vel_mag</th>\n",
       "      <th>buoy_vel_dir</th>\n",
       "      <th>wind_vel_mag</th>\n",
       "      <th>wind_vel_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>1906</td>\n",
       "      <td>0.990195</td>\n",
       "      <td>522.523298</td>\n",
       "      <td>3.189743</td>\n",
       "      <td>78.007070</td>\n",
       "      <td>-128.549129</td>\n",
       "      <td>1.370671</td>\n",
       "      <td>2.191824</td>\n",
       "      <td>6.711849</td>\n",
       "      <td>3.189490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>1913</td>\n",
       "      <td>0.966372</td>\n",
       "      <td>412.767669</td>\n",
       "      <td>2.484009</td>\n",
       "      <td>74.498024</td>\n",
       "      <td>-119.750294</td>\n",
       "      <td>0.741408</td>\n",
       "      <td>0.520564</td>\n",
       "      <td>6.851881</td>\n",
       "      <td>3.240164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>1914</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>362.547379</td>\n",
       "      <td>2.474106</td>\n",
       "      <td>74.003619</td>\n",
       "      <td>-134.786524</td>\n",
       "      <td>1.187695</td>\n",
       "      <td>2.934923</td>\n",
       "      <td>8.896751</td>\n",
       "      <td>3.014921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>1918</td>\n",
       "      <td>0.982681</td>\n",
       "      <td>381.025629</td>\n",
       "      <td>3.740522</td>\n",
       "      <td>81.019593</td>\n",
       "      <td>-145.578020</td>\n",
       "      <td>0.920127</td>\n",
       "      <td>0.028026</td>\n",
       "      <td>1.496117</td>\n",
       "      <td>3.905953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>1906</td>\n",
       "      <td>0.990302</td>\n",
       "      <td>521.535334</td>\n",
       "      <td>3.188522</td>\n",
       "      <td>78.002077</td>\n",
       "      <td>-128.560665</td>\n",
       "      <td>1.300527</td>\n",
       "      <td>1.273525</td>\n",
       "      <td>3.338513</td>\n",
       "      <td>2.278041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329883</th>\n",
       "      <td>339472</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>25560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>470.197315</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>75.686986</td>\n",
       "      <td>-96.341501</td>\n",
       "      <td>17.168005</td>\n",
       "      <td>3.811734</td>\n",
       "      <td>8.234026</td>\n",
       "      <td>3.676847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329884</th>\n",
       "      <td>339473</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>44880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>702.312813</td>\n",
       "      <td>1.517084</td>\n",
       "      <td>86.513431</td>\n",
       "      <td>-29.153877</td>\n",
       "      <td>11.739478</td>\n",
       "      <td>4.628723</td>\n",
       "      <td>6.522125</td>\n",
       "      <td>4.314615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329885</th>\n",
       "      <td>339474</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>53005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>360.491321</td>\n",
       "      <td>1.164462</td>\n",
       "      <td>79.286760</td>\n",
       "      <td>-53.579091</td>\n",
       "      <td>8.973035</td>\n",
       "      <td>3.772087</td>\n",
       "      <td>4.630856</td>\n",
       "      <td>3.224141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329886</th>\n",
       "      <td>339475</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>95020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>393.799208</td>\n",
       "      <td>2.010032</td>\n",
       "      <td>79.025667</td>\n",
       "      <td>-135.924079</td>\n",
       "      <td>2.365742</td>\n",
       "      <td>1.967356</td>\n",
       "      <td>2.240471</td>\n",
       "      <td>0.523007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329887</th>\n",
       "      <td>339476</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>7750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>680.057567</td>\n",
       "      <td>1.511082</td>\n",
       "      <td>86.582037</td>\n",
       "      <td>-23.247546</td>\n",
       "      <td>11.792136</td>\n",
       "      <td>4.703807</td>\n",
       "      <td>5.904344</td>\n",
       "      <td>4.281085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329888 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  year  month  day  doy  id_buoy   sic_cdr         d2c  \\\n",
       "0            0  1979      2   18   49     1906  0.990195  522.523298   \n",
       "1            1  1979      2   18   49     1913  0.966372  412.767669   \n",
       "2            2  1979      2   18   49     1914  0.996022  362.547379   \n",
       "3            3  1979      2   18   49     1918  0.982681  381.025629   \n",
       "4            4  1979      2   19   50     1906  0.990302  521.535334   \n",
       "...        ...   ...    ...  ...  ...      ...       ...         ...   \n",
       "329883  339472  2019     12   30  364    25560  1.000000  470.197315   \n",
       "329884  339473  2019     12   30  364    44880  1.000000  702.312813   \n",
       "329885  339474  2019     12   30  364    53005  1.000000  360.491321   \n",
       "329886  339475  2019     12   30  364    95020  1.000000  393.799208   \n",
       "329887  339476  2019     12   30  364     7750  1.000000  680.057567   \n",
       "\n",
       "        ice_thickness   buoy_lat    buoy_lon  buoy_vel_mag  buoy_vel_dir  \\\n",
       "0            3.189743  78.007070 -128.549129      1.370671      2.191824   \n",
       "1            2.484009  74.498024 -119.750294      0.741408      0.520564   \n",
       "2            2.474106  74.003619 -134.786524      1.187695      2.934923   \n",
       "3            3.740522  81.019593 -145.578020      0.920127      0.028026   \n",
       "4            3.188522  78.002077 -128.560665      1.300527      1.273525   \n",
       "...               ...        ...         ...           ...           ...   \n",
       "329883       0.933125  75.686986  -96.341501     17.168005      3.811734   \n",
       "329884       1.517084  86.513431  -29.153877     11.739478      4.628723   \n",
       "329885       1.164462  79.286760  -53.579091      8.973035      3.772087   \n",
       "329886       2.010032  79.025667 -135.924079      2.365742      1.967356   \n",
       "329887       1.511082  86.582037  -23.247546     11.792136      4.703807   \n",
       "\n",
       "        wind_vel_mag  wind_vel_dir  \n",
       "0           6.711849      3.189490  \n",
       "1           6.851881      3.240164  \n",
       "2           8.896751      3.014921  \n",
       "3           1.496117      3.905953  \n",
       "4           3.338513      2.278041  \n",
       "...              ...           ...  \n",
       "329883      8.234026      3.676847  \n",
       "329884      6.522125      4.314615  \n",
       "329885      4.630856      3.224141  \n",
       "329886      2.240471      0.523007  \n",
       "329887      5.904344      4.281085  \n",
       "\n",
       "[329888 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unzip the zip dataset\n",
    "with zipfile.ZipFile('data/converted.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')\n",
    "\n",
    "# Load the raw data to disk\n",
    "input_path = \"data/converted.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Convert all column names to lower case and display the dataframe \n",
    "df = df.rename(str.lower, axis='columns')\n",
    "df.set_index(\"id_buoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert level_0, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4b7654d0402e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Remove any rows that have buoy velocity/mag =0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"buoy_vel_mag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the dataframe dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   4602\u001b[0m                 \u001b[0;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4603\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4604\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4606\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3495\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3498\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert level_0, already exists"
     ]
    }
   ],
   "source": [
    "# Do some manipulations on the data and clean it (remove rows of all NaNs, remove duplicates, etc.)\n",
    "\n",
    "# Remove any rows that have buoy velocity/mag =0 \n",
    "df = df.drop(df[df[\"buoy_vel_mag\"] == 0].index)\n",
    "df = df.reset_index()\n",
    "\n",
    "# Print the dataframe dimensions\n",
    "print(\"Dataframe final shape: \", df.shape)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the train/test variables that we will use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sea Ice Movement Datasets\n",
      "Target Variables\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buoy_vel_mag</th>\n",
       "      <th>buoy_vel_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.370671</td>\n",
       "      <td>2.191824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741408</td>\n",
       "      <td>0.520564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.187695</td>\n",
       "      <td>2.934923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.920127</td>\n",
       "      <td>0.028026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.300527</td>\n",
       "      <td>1.273525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329883</th>\n",
       "      <td>17.168005</td>\n",
       "      <td>3.811734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329884</th>\n",
       "      <td>11.739478</td>\n",
       "      <td>4.628723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329885</th>\n",
       "      <td>8.973035</td>\n",
       "      <td>3.772087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329886</th>\n",
       "      <td>2.365742</td>\n",
       "      <td>1.967356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329887</th>\n",
       "      <td>11.792136</td>\n",
       "      <td>4.703807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329888 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        buoy_vel_mag  buoy_vel_dir\n",
       "0           1.370671      2.191824\n",
       "1           0.741408      0.520564\n",
       "2           1.187695      2.934923\n",
       "3           0.920127      0.028026\n",
       "4           1.300527      1.273525\n",
       "...              ...           ...\n",
       "329883     17.168005      3.811734\n",
       "329884     11.739478      4.628723\n",
       "329885      8.973035      3.772087\n",
       "329886      2.365742      1.967356\n",
       "329887     11.792136      4.703807\n",
       "\n",
       "[329888 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sea Ice Movement Datasets\")\n",
    "\n",
    "training_targets = df[[\"buoy_vel_mag\",\"buoy_vel_dir\"]]\n",
    "\n",
    "# We will leave the month for now because it could be an indicator of weather/season \n",
    "print(\"Target Variables\")\n",
    "display(training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>month</th>\n",
       "      <th>d2c</th>\n",
       "      <th>ice_thickness</th>\n",
       "      <th>buoy_lat</th>\n",
       "      <th>buoy_lon</th>\n",
       "      <th>wind_vel_mag</th>\n",
       "      <th>wind_vel_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>522.523298</td>\n",
       "      <td>3.189743</td>\n",
       "      <td>78.007070</td>\n",
       "      <td>-128.549129</td>\n",
       "      <td>6.711849</td>\n",
       "      <td>3.189490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>412.767669</td>\n",
       "      <td>2.484009</td>\n",
       "      <td>74.498024</td>\n",
       "      <td>-119.750294</td>\n",
       "      <td>6.851881</td>\n",
       "      <td>3.240164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>362.547379</td>\n",
       "      <td>2.474106</td>\n",
       "      <td>74.003619</td>\n",
       "      <td>-134.786524</td>\n",
       "      <td>8.896751</td>\n",
       "      <td>3.014921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>381.025629</td>\n",
       "      <td>3.740522</td>\n",
       "      <td>81.019593</td>\n",
       "      <td>-145.578020</td>\n",
       "      <td>1.496117</td>\n",
       "      <td>3.905953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>521.535334</td>\n",
       "      <td>3.188522</td>\n",
       "      <td>78.002077</td>\n",
       "      <td>-128.560665</td>\n",
       "      <td>3.338513</td>\n",
       "      <td>2.278041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329883</th>\n",
       "      <td>329883</td>\n",
       "      <td>12</td>\n",
       "      <td>470.197315</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>75.686986</td>\n",
       "      <td>-96.341501</td>\n",
       "      <td>8.234026</td>\n",
       "      <td>3.676847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329884</th>\n",
       "      <td>329884</td>\n",
       "      <td>12</td>\n",
       "      <td>702.312813</td>\n",
       "      <td>1.517084</td>\n",
       "      <td>86.513431</td>\n",
       "      <td>-29.153877</td>\n",
       "      <td>6.522125</td>\n",
       "      <td>4.314615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329885</th>\n",
       "      <td>329885</td>\n",
       "      <td>12</td>\n",
       "      <td>360.491321</td>\n",
       "      <td>1.164462</td>\n",
       "      <td>79.286760</td>\n",
       "      <td>-53.579091</td>\n",
       "      <td>4.630856</td>\n",
       "      <td>3.224141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329886</th>\n",
       "      <td>329886</td>\n",
       "      <td>12</td>\n",
       "      <td>393.799208</td>\n",
       "      <td>2.010032</td>\n",
       "      <td>79.025667</td>\n",
       "      <td>-135.924079</td>\n",
       "      <td>2.240471</td>\n",
       "      <td>0.523007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329887</th>\n",
       "      <td>329887</td>\n",
       "      <td>12</td>\n",
       "      <td>680.057567</td>\n",
       "      <td>1.511082</td>\n",
       "      <td>86.582037</td>\n",
       "      <td>-23.247546</td>\n",
       "      <td>5.904344</td>\n",
       "      <td>4.281085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329888 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        level_0  month         d2c  ice_thickness   buoy_lat    buoy_lon  \\\n",
       "0             0      2  522.523298       3.189743  78.007070 -128.549129   \n",
       "1             1      2  412.767669       2.484009  74.498024 -119.750294   \n",
       "2             2      2  362.547379       2.474106  74.003619 -134.786524   \n",
       "3             3      2  381.025629       3.740522  81.019593 -145.578020   \n",
       "4             4      2  521.535334       3.188522  78.002077 -128.560665   \n",
       "...         ...    ...         ...            ...        ...         ...   \n",
       "329883   329883     12  470.197315       0.933125  75.686986  -96.341501   \n",
       "329884   329884     12  702.312813       1.517084  86.513431  -29.153877   \n",
       "329885   329885     12  360.491321       1.164462  79.286760  -53.579091   \n",
       "329886   329886     12  393.799208       2.010032  79.025667 -135.924079   \n",
       "329887   329887     12  680.057567       1.511082  86.582037  -23.247546   \n",
       "\n",
       "        wind_vel_mag  wind_vel_dir  \n",
       "0           6.711849      3.189490  \n",
       "1           6.851881      3.240164  \n",
       "2           8.896751      3.014921  \n",
       "3           1.496117      3.905953  \n",
       "4           3.338513      2.278041  \n",
       "...              ...           ...  \n",
       "329883      8.234026      3.676847  \n",
       "329884      6.522125      4.314615  \n",
       "329885      4.630856      3.224141  \n",
       "329886      2.240471      0.523007  \n",
       "329887      5.904344      4.281085  \n",
       "\n",
       "[329888 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop the time related columns \n",
    "training_data = df.drop([\"index\", \"year\",\"day\",\"sic_cdr\", \"doy\", \"id_buoy\",\"buoy_vel_mag\",\"buoy_vel_dir\"], axis = 1)\n",
    "display(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate multioutput regression models\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (247416, 8)\n",
      "Test data shape:  (82472, 8)\n",
      "Training labels shape:  (247416, 2)\n",
      "Test labels shape:  (82472, 2)\n"
     ]
    }
   ],
   "source": [
    "# test_size: what proportion of original data is used for test set\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    training_data, training_targets, test_size= 0.25, shuffle=True)\n",
    "\n",
    "# show the sizes of the training and test sets\n",
    "print(\"Training data shape: \", train_data.shape)\n",
    "print(\"Test data shape: \", test_data.shape)\n",
    "\n",
    "print(\"Training labels shape: \", train_labels.shape)\n",
    "print(\"Test labels shape: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual feature do not more or less look like standard normally distributed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98284862, 0.90909091, 0.39605835, ..., 0.87799093, 0.14529321,\n",
       "        0.38285766],\n",
       "       [0.62393069, 0.81818182, 0.41993379, ..., 0.11635646, 0.31671932,\n",
       "        0.4480463 ],\n",
       "       [0.55584657, 0.63636364, 0.39895368, ..., 0.17550422, 0.2372997 ,\n",
       "        0.85258848],\n",
       "       ...,\n",
       "       [0.95424177, 0.45454545, 0.68543246, ..., 0.18031881, 0.2840987 ,\n",
       "        0.33328241],\n",
       "       [0.23763967, 0.54545455, 0.84780578, ..., 0.19399481, 0.22700581,\n",
       "        0.011724  ],\n",
       "       [0.09408099, 0.09090909, 0.06717779, ..., 0.69238708, 0.20566016,\n",
       "        0.56478737]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# display the normalized data\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_multirf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100))\n",
    "regr_multirf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_rf = RandomForestRegressor(n_estimators=100,\n",
    "                                random_state=2)\n",
    "regr_rf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_KNN = KNeighborsRegressor(n_neighbors=20)\n",
    "\n",
    "regr_KNN.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_LR = LinearRegression()\n",
    "regr_LR.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_DT = DecisionTreeRegressor()\n",
    "regr_DT.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the new predictions using the trained models\n",
    "y_multirf = regr_multirf.predict(test_data)\n",
    "y_rf = regr_rf.predict(test_data)\n",
    "y_KNN=regr_KNN.predict(test_data)\n",
    "y_LR=regr_LR.predict(test_data)\n",
    "y_DT=regr_DT.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regr_rf.score(test_data,test_labels))\n",
    "print(regr_multirf.score(test_data, test_labels))\n",
    "print(regr_KNN.score(test_data, test_labels))\n",
    "print(regr_LR.score(test_data, test_labels))\n",
    "print(regr_DT.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests \n",
    "\n",
    "plt.scatter(y_rf, test_labels, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(regr_rf, train_data, train_labels,  scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# force the scores to be positive\n",
    "n_scores = absolute(n_scores)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y given as array_like objects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_multirf, test_labels, alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y given as array_like objects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_KNN, test_labels, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y given as array_like objects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_LR, test_labels, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_DT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dedbb3f18655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_DT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_DT' is not defined"
     ]
    }
   ],
   "source": [
    "# x and y given as array_like objects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_DT, test_labels, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# display the normalized data\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the minimum percentage of the variables such that 95% of the variance in the dataset is retained\n",
    "pca = PCA(n_components=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit PCA on training set. Note: you are fitting PCA on the training set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(train_data)\n",
    "\n",
    "# print the number of components we are left with\n",
    "print(\"Number of components: \", pca.n_components_)\n",
    "print(\"PCA variance ratio: \", pca.explained_variance_ratio_)\n",
    "\n",
    "# Transform the data according to the number of principal components\n",
    "train_data = pca.transform(train_data)\n",
    "test_data = pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the principal component dataframe: \n",
    "principalDf = pd.DataFrame(data = train_data, columns = ['principal component 1', \n",
    "                                                         'principal component 2','principal component 3', 'principal component 4'])\n",
    "\n",
    "# Concatenate the new dataset with the targets\n",
    "finalDf = pd.concat([principalDf, training_targets], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check scikit-learn version\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a series of models and calculate the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different model choices we can use include Linear Regression, K-Nearest Neighbors, Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# define model\n",
    "model = LinearRegression()\n",
    "# fit model\n",
    "model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# define model\n",
    "model = KNeighborsRegressor()\n",
    "# fit model\n",
    "model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# define model\n",
    "model = DecisionTreeRegressor()\n",
    "# fit model\n",
    "model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with K-Cross Validation\n",
    "\n",
    "IMPORT K-FOLD\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3)\n",
    "\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, train_data, train_labels,  scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# force the scores to be positive\n",
    "n_scores = absolute(n_scores)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "#model.predict(test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
