{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Launch Lab - Sea Ice Movement Challenge - PCA and t-SNE analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some more analysis on the data before choosing our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os \n",
    "pd.options.mode.chained_assignment = None\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import modules.ml_pipeline.readdata as mlpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from disk and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (339478, 15)\n"
     ]
    }
   ],
   "source": [
    "# unzip the zip dataset\n",
    "with zipfile.ZipFile('data/data-sea-ice.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')\n",
    "\n",
    "# Load the raw data to disk\n",
    "input_path = \"data/DRIFT_DATA_TRAIN.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Convert all column names to lower case and display the dataframe \n",
    "df = df.rename(str.lower, axis='columns')\n",
    "df.set_index(\"id_buoy\")\n",
    "\n",
    "# Print the dataframe dimensions\n",
    "print(\"Dataframe shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping the NaNs : (339478, 15)\n",
      "After dropping the NaNs : (339478, 15)\n",
      "After dropping the duplicates: (339203, 15)\n"
     ]
    }
   ],
   "source": [
    "# Do some manipulations on the data and clean it (remove rows of all NaNs, remove duplicates, etc.)\n",
    "\n",
    "# Dropping the NA when there is no value on the current columns\n",
    "print(\"Before dropping the NaNs :\", df.shape)\n",
    "df = df.dropna(how=\"any\", subset=[\"u_buoy\", \"v_buoy\"])\n",
    "print(\"After dropping the NaNs :\", df.shape)\n",
    "\n",
    "# Remove Duplicates \n",
    "df = df.drop_duplicates() \n",
    "\n",
    "# Fill the missing values with the median value \n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "# Print size of the df after dropping duplicates\n",
    "print(\"After dropping the duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>doy</th>\n",
       "      <th>x_ease</th>\n",
       "      <th>y_ease</th>\n",
       "      <th>u_buoy</th>\n",
       "      <th>v_buoy</th>\n",
       "      <th>id_buoy</th>\n",
       "      <th>u_era5</th>\n",
       "      <th>v_era5</th>\n",
       "      <th>sic_cdr</th>\n",
       "      <th>h_cs2smos</th>\n",
       "      <th>h_piomas</th>\n",
       "      <th>d2c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>147.506958</td>\n",
       "      <td>138.582672</td>\n",
       "      <td>-0.797554</td>\n",
       "      <td>1.114740</td>\n",
       "      <td>1906</td>\n",
       "      <td>-6.704156</td>\n",
       "      <td>-0.321260</td>\n",
       "      <td>0.990195</td>\n",
       "      <td>1.774046</td>\n",
       "      <td>3.189743</td>\n",
       "      <td>522.523298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>146.834778</td>\n",
       "      <td>120.509880</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.368754</td>\n",
       "      <td>1913</td>\n",
       "      <td>-6.818630</td>\n",
       "      <td>-0.674205</td>\n",
       "      <td>0.966372</td>\n",
       "      <td>1.774046</td>\n",
       "      <td>2.484009</td>\n",
       "      <td>412.767669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>130.993561</td>\n",
       "      <td>129.623672</td>\n",
       "      <td>-1.162420</td>\n",
       "      <td>0.243717</td>\n",
       "      <td>1914</td>\n",
       "      <td>-8.825469</td>\n",
       "      <td>1.123955</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>1.774046</td>\n",
       "      <td>2.474106</td>\n",
       "      <td>362.547379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>147.524719</td>\n",
       "      <td>157.382492</td>\n",
       "      <td>0.919766</td>\n",
       "      <td>0.025784</td>\n",
       "      <td>1918</td>\n",
       "      <td>-1.079951</td>\n",
       "      <td>-1.035410</td>\n",
       "      <td>0.982681</td>\n",
       "      <td>1.774046</td>\n",
       "      <td>3.740522</td>\n",
       "      <td>381.025629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>147.470963</td>\n",
       "      <td>138.599823</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>1.243485</td>\n",
       "      <td>1906</td>\n",
       "      <td>-2.169171</td>\n",
       "      <td>2.537787</td>\n",
       "      <td>0.990302</td>\n",
       "      <td>1.774046</td>\n",
       "      <td>3.188522</td>\n",
       "      <td>521.535334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339473</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>193.232056</td>\n",
       "      <td>172.742004</td>\n",
       "      <td>-0.981225</td>\n",
       "      <td>-11.698400</td>\n",
       "      <td>44880</td>\n",
       "      <td>-2.526544</td>\n",
       "      <td>-6.012877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414148</td>\n",
       "      <td>1.620020</td>\n",
       "      <td>702.312813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339474</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>208.421234</td>\n",
       "      <td>142.049896</td>\n",
       "      <td>-7.247925</td>\n",
       "      <td>-5.289890</td>\n",
       "      <td>53005</td>\n",
       "      <td>-4.615093</td>\n",
       "      <td>-0.381765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.039972</td>\n",
       "      <td>1.288953</td>\n",
       "      <td>360.491321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339475</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>145.264023</td>\n",
       "      <td>146.109741</td>\n",
       "      <td>-0.913761</td>\n",
       "      <td>2.182150</td>\n",
       "      <td>95020</td>\n",
       "      <td>1.940967</td>\n",
       "      <td>1.119087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.059716</td>\n",
       "      <td>1.960349</td>\n",
       "      <td>393.799208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339476</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>193.921402</td>\n",
       "      <td>174.408707</td>\n",
       "      <td>-0.101372</td>\n",
       "      <td>-11.791700</td>\n",
       "      <td>7750</td>\n",
       "      <td>-2.468425</td>\n",
       "      <td>-5.363596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.411272</td>\n",
       "      <td>1.610893</td>\n",
       "      <td>680.057567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339477</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>100.407974</td>\n",
       "      <td>159.768845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>16461</td>\n",
       "      <td>1.372457</td>\n",
       "      <td>7.310530</td>\n",
       "      <td>0.949975</td>\n",
       "      <td>1.221326</td>\n",
       "      <td>1.339197</td>\n",
       "      <td>11.722729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339203 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  month  day  doy      x_ease      y_ease    u_buoy     v_buoy  \\\n",
       "0       1979      2   18   49  147.506958  138.582672 -0.797554   1.114740   \n",
       "1       1979      2   18   49  146.834778  120.509880  0.643200   0.368754   \n",
       "2       1979      2   18   49  130.993561  129.623672 -1.162420   0.243717   \n",
       "3       1979      2   18   49  147.524719  157.382492  0.919766   0.025784   \n",
       "4       1979      2   19   50  147.470963  138.599823  0.380940   1.243485   \n",
       "...      ...    ...  ...  ...         ...         ...       ...        ...   \n",
       "339473  2019     12   30  364  193.232056  172.742004 -0.981225 -11.698400   \n",
       "339474  2019     12   30  364  208.421234  142.049896 -7.247925  -5.289890   \n",
       "339475  2019     12   30  364  145.264023  146.109741 -0.913761   2.182150   \n",
       "339476  2019     12   30  364  193.921402  174.408707 -0.101372 -11.791700   \n",
       "339477  2019     12   30  364  100.407974  159.768845  0.000000  -0.000000   \n",
       "\n",
       "        id_buoy    u_era5    v_era5   sic_cdr  h_cs2smos  h_piomas         d2c  \n",
       "0          1906 -6.704156 -0.321260  0.990195   1.774046  3.189743  522.523298  \n",
       "1          1913 -6.818630 -0.674205  0.966372   1.774046  2.484009  412.767669  \n",
       "2          1914 -8.825469  1.123955  0.996022   1.774046  2.474106  362.547379  \n",
       "3          1918 -1.079951 -1.035410  0.982681   1.774046  3.740522  381.025629  \n",
       "4          1906 -2.169171  2.537787  0.990302   1.774046  3.188522  521.535334  \n",
       "...         ...       ...       ...       ...        ...       ...         ...  \n",
       "339473    44880 -2.526544 -6.012877  1.000000   1.414148  1.620020  702.312813  \n",
       "339474    53005 -4.615093 -0.381765  1.000000   1.039972  1.288953  360.491321  \n",
       "339475    95020  1.940967  1.119087  1.000000   2.059716  1.960349  393.799208  \n",
       "339476     7750 -2.468425 -5.363596  1.000000   1.411272  1.610893  680.057567  \n",
       "339477    16461  1.372457  7.310530  0.949975   1.221326  1.339197   11.722729  \n",
       "\n",
       "[339203 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop the time related columns \n",
    "training_data = df.drop([\"year\",\"day\", \"doy\", \"id_buoy\",\"u_buoy\", \"v_buoy\"], axis = 1)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sea Ice Movement Datasets\n",
      "Target Variables\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_buoy</th>\n",
       "      <th>v_buoy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.797554</td>\n",
       "      <td>1.114740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.368754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.162420</td>\n",
       "      <td>0.243717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.919766</td>\n",
       "      <td>0.025784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380940</td>\n",
       "      <td>1.243485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339473</th>\n",
       "      <td>-0.981225</td>\n",
       "      <td>-11.698400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339474</th>\n",
       "      <td>-7.247925</td>\n",
       "      <td>-5.289890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339475</th>\n",
       "      <td>-0.913761</td>\n",
       "      <td>2.182150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339476</th>\n",
       "      <td>-0.101372</td>\n",
       "      <td>-11.791700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339477</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339203 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          u_buoy     v_buoy\n",
       "0      -0.797554   1.114740\n",
       "1       0.643200   0.368754\n",
       "2      -1.162420   0.243717\n",
       "3       0.919766   0.025784\n",
       "4       0.380940   1.243485\n",
       "...          ...        ...\n",
       "339473 -0.981225 -11.698400\n",
       "339474 -7.247925  -5.289890\n",
       "339475 -0.913761   2.182150\n",
       "339476 -0.101372 -11.791700\n",
       "339477  0.000000  -0.000000\n",
       "\n",
       "[339203 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sea Ice Movement Datasets\")\n",
    "\n",
    "training_targets = df[[\"u_buoy\", \"v_buoy\"]]\n",
    "\n",
    "# We will leave the month for now because it could be an indicator of weather/season \n",
    "print(\"Target Variables\")\n",
    "display(training_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a Training and Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (254402, 9)\n",
      "Test data shape:  (84801, 9)\n"
     ]
    }
   ],
   "source": [
    "# test_size: what proportion of original data is used for test set\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    training_data, training_targets, test_size= 0.25, shuffle=True)\n",
    "\n",
    "# show the sizes of the training and test sets\n",
    "print(\"Training data shape: \", train_data.shape)\n",
    "print(\"Test data shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA to Speed up Machine Learning Algorithms\n",
    "(Taken from https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60)\n",
    "\n",
    "Since PCA yields a feature subspace that maximizes the variance along the axes, it makes sense to standardize the data, especially, if it was measured on different scales.\n",
    "\n",
    "Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual feature do not more or less look like standard normally distributed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.23031761e+00, -1.08873463e+00,  6.99113093e-02, ...,\n",
       "         2.04385353e+00, -2.94410800e-01, -1.12616491e+00],\n",
       "       [ 9.40664076e-01,  1.28102400e+00,  2.42684875e-01, ...,\n",
       "        -2.42845952e+00, -9.73318229e-01,  1.15599880e+00],\n",
       "       [ 3.61357016e-01,  1.68343286e-01, -5.75596488e-01, ...,\n",
       "        -1.51224505e-04,  8.78071404e-03,  2.04933547e+00],\n",
       "       ...,\n",
       "       [-7.97257103e-01, -3.57784357e-01,  2.70097861e+00, ...,\n",
       "        -1.51224505e-04, -1.64220498e+00, -1.58311851e+00],\n",
       "       [-1.66621769e+00,  7.39694147e-01, -1.57656278e+00, ...,\n",
       "        -2.35577889e+00, -3.93770949e-01, -1.33694129e+00],\n",
       "       [ 1.51997114e+00, -8.72035474e-01, -1.43431689e-01, ...,\n",
       "        -1.51224505e-04,  1.07857995e+00, -5.15347139e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# display the normalized data\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the minimum percentage of the variables such that 95% of the variance in the dataset is retained\n",
    "pca = PCA(n_components=3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit PCA on training set. Note: you are fitting PCA on the training set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components:  3\n",
      "PCA variance ratio:  [0.19299088 0.15966511 0.14868213]\n"
     ]
    }
   ],
   "source": [
    "pca.fit(train_data)\n",
    "\n",
    "# print the number of components we are left with\n",
    "print(\"Number of components: \", pca.n_components_)\n",
    "print(\"PCA variance ratio: \", pca.explained_variance_ratio_)\n",
    "\n",
    "# Transform the data according to the number of principal components\n",
    "train_data = pca.transform(train_data)\n",
    "test_data = pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the principal component dataframe: \n",
    "principalDf = pd.DataFrame(data = train_data, columns = ['principal component 1', \n",
    "                                                         'principal component 2','principal component 3'])\n",
    "\n",
    "# Concatenate the new dataset with the targets\n",
    "finalDf = pd.concat([principalDf, training_targets], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
